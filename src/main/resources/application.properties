spring.kafka.bootstrap-servers=172.168.83.111:9092,172.168.83.112:9092,172.168.83.113:9092
#消费监听器容器并发数
spring.kafka.listener.concurrency=3
#用于配置发送失败的重试次数,默认值:0。
spring.kafka.producer.retries=0
spring.kafka.producer.compression-type=

#即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
spring.kafka.producer.acks=all
#用于批量提交的batch字节大小，默认值为:16384。
spring.kafka.producer.batch-size=16384
#用于配置producer端等待向server发送的数据的缓冲区的大小，默认值为:32MB。
spring.kafka.producer.buffer-memory=33554432
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer



# 消费者群组ID，发布-订阅模式，即如果一个生产者，多个消费者都要消费，那么需要定义自己的群组，同一群组内的消费者只有一个能消费到消息
spring.kafka.consumer.group-id=myGroup

#earliest
#当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
#latest
#当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
#none
#topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
#反序列化信任包 参数可以填写为*
spring.kafka.consumer.properties.spring.json.trusted.packages=cn.eakay.springboot.client